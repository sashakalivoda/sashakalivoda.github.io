---
layout: post
title: "Wordle and Probability"
subtitle: "Is 'CARES' the best word to start with?"
background: '/img/posts/wordle/second try.png'
---

**Note: The data used and this article was created before the New York Times purchased Wordle.**


## How to play

I, like many others, am obsessed with Wordle. The game is simple: you have six guesses to solve one five-letter word. With each guess, the background of the letter turns either green, yellow, or white/black (depending on whether your phone is on light or dark mode). Green tells you that the letter is in the word and in the right position. Yellow tells you that the letter is in the word but it isn't in that position. White/black tells you that the letter is not in the word at all. Using the clues given and good choice of guesses, you shoud be able to guess the word within six tries. But what is the best way to get the word in the least amount of tries?

## Background

One day I was talking to my friend and she told me that her teacher created a program that would give a list of possible words with every guess you make. So you would guess the word and then input the color pattern and then using what information is given, the program would narrow down the list of all possible five-letter words to only the ones possible. This sounded like a fun little challenge for me to make at home so I decided to go ahead and try it. But I also wondered, what if it could suggest the most likely answer? 

But how does one figure out the most likely answer? The game is tricky because at the start of the game you want to guess words with letters that are likely to be in the word and can narrow down the possibilities. Many people guess words with a lot of vowels such as AUDIO or ADIEU so that they can narrow down which vowels are in the word. This is a great tactic, even though they sacrifice a guess, knowing that the first word is never going to be correct (It's possible that the answer could one day be AUDIO, but ADIEU is French and is not a possible solution). Then there are the consonants that show up the most often in words such as S, R, T, N, and L. These letters show up most often in the English language, but does it apply to five-letter words? Also, the words that are the solutions to Wordle are specifically chosen. The solution list is a list of five-letter words *a fifth* of the size of all five-letter words. 

Are the letters in the solutions list as common as the letters in all possible five-letter words? This is what I set to figure out. 


## Import the necessary packages

We are going to need these packages for later on so we should import them now. 



```python
  import pandas as pd
  import numpy as np
  from string import ascii_lowercase 
  import matplotlib.pyplot as plt
  import seaborn as sns

```


## Creating a file of five-letter words

I looked for a list of five-letter words all over the internet but I came up with nothing (now there's a list on Kaggle made specifically for Wordle). Instead I had to get a file of all English words and then cut out the words that are longer than five letters. I found the file on Github on this [page](https://github.com/dwyl/english-words). As you can imagine, the file size of the list of English words is massive and it takes a while to parse through it, so I would suggest saving it as a separate file. 


```python
  data = []
  words = []

  with open('words_alpha.txt') as f:
      data = f.read().split('\n')
```


```python
  for word in data:
      if len(word) == 5:
          words.append(word)
```


```python
  df = pd.DataFrame(words)
  df.to_csv('words.csv',index=False)
```


```python
  # Check
  file = pd.read_csv('words.csv')
  file.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>aahed</td>
    </tr>
    <tr>
      <th>1</th>
      <td>aalii</td>
    </tr>
    <tr>
      <th>2</th>
      <td>aargh</td>
    </tr>
    <tr>
      <th>3</th>
      <td>aaron</td>
    </tr>
    <tr>
      <th>4</th>
      <td>abaca</td>
    </tr>
  </tbody>
</table>
</div>

```python

```


## Comparing lists

The benefit of the Wordle solution list being set is that there is a list of the solutions on the internet so we can actually compare all the solutions to the list of all possible words. I got the list of solutions to Wordle [here](https://controlc.com/8fbd6bfd).

To start, we break up the list of all five-letter words into a dictionary of the letters and the count of those letters. We will also do that with the list of Wordle solutions. To be able to do that we had to parse through all the words and split each word into five letters. For each letter that was counted, the count increased by one. 


```python
  #Creating a dictionary of letters and the counts of the letters 
  letters = list(ascii_lowercase)
  numbers = [0]*26

  words_dict = dict(zip(letters, numbers))
  wordle_dict = dict(zip(letters, numbers))

  # Creating list of five-letter words
  df = pd.read_csv('words.csv')
  word_list = df.iloc[:, 0].tolist()

  # Creating list of Worldle solutions
  wordle = pd.read_csv('Wordle words.csv')
  wordle_list = wordle.iloc[:, 0].tolist()
```


```python
  #Counting the number of letters in the word lists
  for word in word_list:
      for char in word:
          for key in words_dict.keys():
              if char == key:
                  words_dict[key]+=1
                
  for word in wordle_list:
      for char in word:
          for key in wordle_dict.keys():
              if char == key:
                  wordle_dict[key]+=1
```


We can now check that the dictionary does have a count for the letters.




```python
  words_dict
```




      {'a': 8392,
       'b': 2089,
       'c': 2744,
       'd': 2811,
       'e': 7800,
       'f': 1238,
       'g': 1971,
       'h': 2284,
       'i': 5067,
       'j': 376,
       'k': 1743,
       'l': 4246,
       'm': 2494,
       'n': 4043,
       'o': 5219,
       'p': 2299,
       'q': 139,
       'r': 5143,
       's': 6537,
       't': 4189,
       'u': 3361,
       'v': 878,
       'w': 1171,
       'x': 361,
       'y': 2521,
       'z': 474}



We can see that it's working, but it's hard to see how they are different. So we can now put them into graphs. 

    
![png](/img/posts/wordle/output_13_0.png)
    


Before we analyze these graphs, we need to take into account the size of the y-axis. The y-axis of the count of all five-letter words is larger by 2000. It makes sense that the list of Wordle solutions has a smaller count for all numbers since it's a subset of the other list. 

We can see that the frequency of letters between the two lists is similar, but not exact. For the Wordle solutions, the letter 'S' appears much more frequently than in the list of all possible words (although the number of S's are similar). We also see that the vowel 'E' appears more frequently than the vowel 'A' in the Wordle solutions list. 

## Letter Probability and Position

After doing this, I wanted to know which positions of the letters was most common for each letter. For example, it's more common for a word to have a vowel in the middle of the word than at the start of one. I wanted to see if there were some letters that had a stronger probability of being in a certain position than others. 

To do that we had to split each word by the letters and determine the index of that letter. Then, as we did with the previous count, it's increased by one each time there's a match. This is defined by the Locator function which creates a dictionary for each letter and it's positions. 

Then to find the probability of a letter in a certain position we need to have the probability of the letter multiplied by the probability of the letter in that specific position. The probability of the letter is the count of the letter divided by the total number of letters. The probability of the letter in the specific position is the count of the letter in the position divided by the count of the letter itself. Then we create a nested dictionary of the letters and each of the postions and it's probability. 


```python
  def word_locator(letter):
      letter_loc = {0:0,1:0,2:0,3:0,4:0}
      for word in word_list:
          for char in word:
              if char == letter:
                  for key in letter_loc:
                      if key == word.index(char):
                          letter_loc[key]+=1
      return letter_loc

  def wordle_locator(letter):
      letter_loc = {0:0,1:0,2:0,3:0,4:0}
      for word in wordle_list:
          for char in word:
              if char == letter:
                  for key in letter_loc:
                      if key == word.index(char):
                          letter_loc[key]+=1
      return letter_loc
```


      E located in word list:  {0: 616, 1: 2574, 2: 1054, 3: 2121, 4: 1435}
      E located in Wordle:  {0: 458, 1: 2189, 2: 908, 3: 1961, 4: 1145}

      Count of the letter E in Words list:  7800
      Count of the letter E in Wordle list:  6661

      Probability of E in the third position in words list:  0.013242869707249652
      Probability of E in the third position in Worldle:  0.013999383287079864


```python
  wordle_total_prob = []
  for letter in letters:
      num_of_letters = wordle_dict[letter]
      p_of_letter = [num_of_letters/(len(wordle_list)*5)]*5
      p_of_position = []
      for i in range(5):
          p_of_position.append(wordle_locator(letter)[i]/num_of_letters)
    
      ar1 = np.array(p_of_letter)
      ar2 = np.array(p_of_position)
      wordle_total_prob.append(ar1*ar2)
    

  words_total_prob = []
  for letter in letters:
      num_of_letters = words_dict[letter]
      p_of_letter = [num_of_letters/(len(word_list)*5)]*5
      p_of_position = []
      for i in range(5):
          p_of_position.append(word_locator(letter)[i]/num_of_letters)
    
      ar1 = np.array(p_of_letter)
      ar2 = np.array(p_of_position)
      words_total_prob.append(ar1*ar2)
```


    
![png](/img/posts/wordle/output_23_0.png)
    


The heatmap makes it easier to compare the probability of all letters in different positions. From what I see, the biggest change is in the letter 'S' where the probability of the word ending in 'S' with the Wordle solutions is 5.2%.

It's also interesting to see how the probability of the vowels are higher in the second and fourth position of the word, especially with the letters 'A' and 'O' which is much more probable of being in the second position than any other position. Another letter to look at is the letter 'Y', which is much more likely to end with the letter than in any other position. 

## Word Probability and Word Choice

Knowing the probability of the letters in each of the posiitons is great and all, but what is the benefit of it? Can we figure out what word is the most probable? Can we determine the best starting word for the game with the probabilities?

Let's try to figure out the most probable word. By parsing through the list, we can apply the probability of each word by combining the probability of each letter.


```python
  p_word = []
  for word in word_list:
      p = 1
      for char in word:
          i = word.index(char)
          for key in words_position_prob.keys():
              if char == key:
                  p = p*(words_position_prob[char][i])
      p_word.append(p)
```


```python
  d = dict(zip(word_list,p_word))
  word_data = pd.DataFrame([d],index=['Probability']).transpose()
  word_data = word_data.sort_values('Probability',ascending=False)
  word_data.head(8)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Probability</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>sarsa</th>
      <td>2.993687e-08</td>
    </tr>
    <tr>
      <th>sarra</th>
      <td>2.231955e-08</td>
    </tr>
    <tr>
      <th>salsa</th>
      <td>2.189877e-08</td>
    </tr>
    <tr>
      <th>sassy</th>
      <td>1.891964e-08</td>
    </tr>
    <tr>
      <th>saree</th>
      <td>1.761153e-08</td>
    </tr>
    <tr>
      <th>taata</th>
      <td>1.737462e-08</td>
    </tr>
    <tr>
      <th>cacas</th>
      <td>1.713602e-08</td>
    </tr>
    <tr>
      <th>sooey</th>
      <td>1.699491e-08</td>
    </tr>
  </tbody>
</table>
</div>

```python

```


When finding the most probable word, we see that words that have the letter 'S' and 'A' repeating are in the first couple of words since we are basing this off the probability of the letters in their positions. Since 'S' and 'R' are the most common consonants we see them repeating often, as well as the vowels that are very common like 'A' and 'E'. 

But with the game, we know that SARSA or SARRA isn't going to be a solution, nor is it a good word to guess to start the game. Words that are good to guess are probable but also contain a variety of letters since you are able to narrow down what letters are in the solution or not. 

We're going to edit the program a little bit so that when the word repeats a letter, the 'probability' isn't affected. I put 'probability' in quotes because the probabilities are going to be summed for the letters in the positions and then add 0 if the letters are repeated. This will make all words with repeated letters head to the bottom of the list, but it won't be an accurate representation of the probability. 


```python
  p_word = []
  for word in word_list:
      p = 0
      for char in word:
          i = word.index(char)
          for key in words_position_prob.keys():
                  if char == key:
                      if word.count(char)>1:
                          p+=0
                      else:
                          p+=(words_position_prob[char][i])
        
      p_word.append(p)
```


```python
  d2 = dict(zip(word_list,p_word))
  word_data_2 = pd.DataFrame([d2],index=['"Probability"']).transpose()
  word_data_2 = word_data_2.sort_values('"Probability"',ascending=False)
  word_data_2.head(8)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>"Probability"</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>cares</th>
      <td>0.140684</td>
    </tr>
    <tr>
      <th>bares</th>
      <td>0.139553</td>
    </tr>
    <tr>
      <th>tares</th>
      <td>0.138686</td>
    </tr>
    <tr>
      <th>pares</th>
      <td>0.137052</td>
    </tr>
    <tr>
      <th>canes</th>
      <td>0.136474</td>
    </tr>
    <tr>
      <th>mares</th>
      <td>0.135746</td>
    </tr>
    <tr>
      <th>banes</th>
      <td>0.135344</td>
    </tr>
    <tr>
      <th>dares</th>
      <td>0.135319</td>
    </tr>
  </tbody>
</table>
</div>

```python

```


This is a much better word list for the game. CARES has letter with the highest probability in the best position without repeating any letters. A lot of the top words end with the letter 'S', has the vowels 'A' and 'E' in the second and fourth position, and has the most common consonants in the other positions. These word choices have a lot of common letters and will help narrow down the solution much faster than other guesses.

## So what is the best word to start with?

It's hard to say what the best word is to start with because it depends on more factors than just probability. CARES is the most probable that also doesn't repeat letters and is a very decent word to start with. Another good word to start with is ADIEU or AUDIO since these words contain most of the vowels and if you figure out what vowels are in the word, then you can narrow down the solution faster.

Luck is also a factor though. You might be a good guesser or code-breaker, but if you guess a random word and manage to nail an uncommon letter, that rapidly decreases the number of words that the solution can be. 

Something that is interesting and I might try to figure out is what is the best information/color to recieve? Which narrows down the most? Yellow, green or black/white? It's definitely dependant on the letter so that's why I think it would be a good idea to follow this little experiment since what I've done is probably most of the hard work. 

**Thank you for reading this data analysis post! I am always learning and willing to learn so if you have any constructive criticism or comments, please feel free to contact me!**
